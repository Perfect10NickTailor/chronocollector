# logging configures logging parameters for the collector. 
logging:
# level is the level of verbosity that the collector will emit --> Default is `info`. 
  level: ${LOGGING_LEVEL:info}

# metrics configuration - configures how the collector emits metrics.
# Note: These metrics are produced by the collector itself. 
metrics:
  # scope configures how metric names will be formed.
  scope:
    # prefix defines prefix for all metric names. 
    prefix: "chronocollector"
    # tags define custom tags that will be attached to every metric from the collector.
    tags: {}
  # prometheus defines options for the Prometheus reporter.  
  prometheus:
    # handlerPath is the route on which metrics will be served.
    handlerPath: /metrics
  # sanitization indicates that metrics will be in the Prometheus format. 
  sanitization: prometheus
  # samplingRate is the rate at which metrics will be sampled. Default is 1.0.
  samplingRate: 1.0
  # extended configures extra process level metrics that will be emitted. 
  # Options include: none, simple, moderate, detailed, See below link for more information on options: 
  # https://bit.ly/39v2yOO 
  extended: none

# wrapper configuration - configuration for the collector wrapper.
wrapper:
  # listenAddress is the address that collector wrapper will serve requests on. Currently supports /metrics if enabled.
  listenAddress: "${LISTEN_ADDRESS:0.0.0.0:3029}"
  logFilter:
    # enables the log filtering configuration.
    enabled: ${LOG_FILTERING_ENABLED:false}
  # metrics configuration - configures how the collector wrapper emits metrics.
  # Note: These metrics are produced by the collector itself.
  metrics:
    # scope configures how metric names will be formed.
    scope:
      # prefix defines prefix for all metric names.
      prefix: "chronocollector"
      # tags define custom tags that will be attached to every metric from the collector.
      tags: {}
    # prometheus defines options for the Prometheus reporter.
    prometheus:
      # handlerPath is the route on which metrics will be served.
      handlerPath: /metrics
    # sanitization indicates that metrics will be in the Prometheus format.
    sanitization: prometheus
    # samplingRate is the rate at which metrics will be sampled. Default is 1.0.
    samplingRate: 1.0
    # extended configures extra process level metrics that will be emitted.
    # Options include: none, simple, moderate, detailed, See below link for more information on options:
    # https://bit.ly/39v2yOO
    extended: none

# listenAddress is the address that collector will serve requests on. Currently supports /metrics and the remote write endpoint if enabled. 
listenAddress: "${LISTEN_ADDRESS:0.0.0.0:3030}"

# labels defines key value pairs that will be appended to each metric being sent to the Chronosphere backend. 
labels:
  # defaults defines the default labels. 
  defaults:
    chronosphere_k8s_cluster: ${KUBERNETES_CLUSTER_NAME:""}
    organization: "{{ chronocollector.labels.organization }}"

# backend defines what backend the collector forwards metrics to. The chronogateway is the main backend for Chronosphere. The below is needed to configure and send metrics to the `chronogateway`.
backend:
  # type controls which backend configuration to read from. It can either be `gateway` or `prometheusRemoteWrite`.
  type: ${BACKEND_TYPE:gateway}
  # annotatedMetrics controls whether the backend supports annotated metrics in which case the collector will use an annotated write request to send the metrics.
  annotatedMetrics: ${BACKEND_ANNOTATED_METRICS:false}
  gateway:
    # address is `company.chronosphere.io:443`. 
    #address: ${GATEWAY_ADDRESS:""}
    address: {{ gateway_addresses }}
    # insecure determines whether or not metrics are allowed via an insecure connection.
    # Note: Setting to `false` ensures that forwarding metrics are not allowed via an insecure connection. This should only be set to `true` for development purposes.
    insecure: ${GATEWAY_INSECURE:false}
    # cert and certSkipVerify are both related to the TLS. cert allows specifying a certificate chain for the CA.
    # certSkipVerify allows skipping the TLS verification.
    # Note: both cert and certSkipVerify are hardly ever used / used primarily for tesing. 
    # The config is set to use the system’s default “certificate pool”, but fields can be altered if there are special requirements or a non-standard cert setup.
    cert: ${GATEWAY_CERT:""}
    certSkipVerify: ${GATEWAY_CERT_SKIP_VERIFY:false}
    apiTokenFile: {{ api_token_file }}
  
# In order to send metrics to the Prometheus remote write backend (vs. through the `chronogateway`), then uncomment the below section and change type to `prometheusRemoteWrite`.
# backend:
#  type: prometheusRemoteWrite 
#  prometheusRemoteWrite:
     # writeURL is the Prometheus remote write endpoint that metrics will be written to. This will typically be an m3coordinator.
#    writeURL: ${PROMETHEUS_REMOTE_WRITE_ADDRESS:""}
     # httpClientTimeout is the deadline for the Prometheus remote write backend to accept the remote write request.  
#    httpClientTimeout: ${PROMETHEUS_REMOTE_WRITE_HTTP_CLIENT_TIMEOUT:30s}
     # userAgent is the HTTP user agent that the collector will send requests with. 
#    userAgent: ${PROMETHEUS_REMOTE_WRITE_USER_AGENT:chronosphere.io/chronocollector}

# discovery controls how the collector will discover targets to scrape. 
discovery:
  # kubernetes defines settings for discovering targets in the same Kubernetes cluster the collector is running in. 
  kubernetes:
    # enabled indicates whether Kubernetes discovery is enabled. 
    enabled: false
# The collector config can also be set to scrape a static Prometheus endpoint. 
# Note: Kubernetes and Prometheus discovery can be enabled at the same time. 
# In order to use this functionality, uncomment the below section, and make sure the target is updated to the correct endpoint.
# See the below for an example of a target that scrapes a node_exporter listening on "localhost:9100".
  prometheus:
    enabled: true
    scrape_configs:
      # job_name: The job name assigned to scraped metrics by default.
     - job_name: 'nicktailor_hosts'
       # scrape_interval: How frequently to scrape targets from this job.
       scrape_interval: 30s
        # scrape_timeout: Per-scrape timeout when scraping this job.
       scrape_timeout: 30s
        # static_configs: List of labeled statically configured targets for this job.
       static_configs:
        #    Note: make sure to update the target to correct endpoint.
         - targets: [{{ targets_hosts }}]

# See another Prometheus config example here - https://github.com/chronosphereio/collector#prometheus. 

# Push configures push mechanisms to send metrics.
# prometheusRemoteWrite is configuration for prometheus remote write, that allows forwarding remote write requests to Chronosphere.
# Remote write endpoint will be available at /remote/write
# push:
  # prometheusRemoteWrite is configuration for prometheus remote write, that allows forwarding remote write requests to Chronosphere.
  # Remote write endpoint will be available at /remote/write
  # prometheusRemoteWrite:
  #   enabled: true
  # statsd is configuration for sending statsd metrics to Chronosphere. It is hosted as a UDP server at the provided listen address.
  # statsd:
  #   enabled: true
  #   listenAddress: 0.0.0.0:3031
    # optional push interval controls how frequently metrics are pushed to the backend (Default 1s), if the packet size limit is not hit.
    # pushInterval: 1s
    # optional prefix adds a prefix to all statsd metrics pushed.
    # prefix: "staging.foo"

# scrape is the global scrape config. It is not tied to a single job, and can be overridden with annotations and the job config. 
# Visit the Scrape Config section under Collector documentation for more information.
# scrape:
# defaults are the global scrape options when none other are configured. 
#    defaults:
#       metricsPath: "/metrics"
#       scheme: "http"
#       scrapeInterval: "10s"
#       scrapeTimeout: "10s"
#       honorLabels: "false"
#       honorTimestamps: "true"
#       relabels: <relabel_config>
#       metricRelabels: <relabel_config>

















